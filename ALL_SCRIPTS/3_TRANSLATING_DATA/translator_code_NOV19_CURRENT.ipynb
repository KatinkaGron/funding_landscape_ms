{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import deepl\n",
    "import re as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import translators as ts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "# check \n",
    "%matplotlib inline\n",
    "import numbers\n",
    "import string\n",
    "from langdetect import detect\n",
    "from tabulate import tabulate\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from pandas.errors import ParserError\n",
    "from langdetect import DetectorFactory\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder #maybe dont' need\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, hamming_loss, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"grant_dataset_6nov_newheader.csv\", dtype=object)  #reading in the data \n",
    "print(\"shape of loaded dataset : \", df.shape)\n",
    "# Translation - 2 steps\n",
    "\n",
    "#1. langauge detection\n",
    "#2. if language not english = save and translate\n",
    "#We want to translate 3 text types = Titles, Descriptions and (\"Receiver + Title\")\n",
    "\n",
    "#_ = ts.preaccelerate_and_speedtest() #preacceleration step for translation\n",
    "#1 Filter out grant entities with insufficient data\n",
    "#2 Tranlsation\n",
    "\n",
    "\n",
    "\n",
    "#1 filter out bad grant entities\n",
    "\n",
    "def fun_remove_lines2(column):\n",
    "    \"\"\"\n",
    "    This function returns a mask where True indicates the presence of valid data in the column,\n",
    "    and False indicates missing or invalid data.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = ~column.isna() & (column != \"#NA\") & (column != \"-\") & (column != \"Ã…rstal\") & (column.astype(str).str.strip() != \"\")\n",
    "    return mask\n",
    "\n",
    "def higher_remove_function2(amount, year, receiver_1, receiver_name, receiver_title, receiver_inst, descr, title):\n",
    "\n",
    "    \"\"\"\n",
    "    This function incorporates the mask from remove_lines function, and keep lines that have documented:\n",
    "    1. Grant size and year\n",
    "    2. A receiver (name, organisation name, profession or institution)\n",
    "    3. A project description or title (Title, description, or combined text of receiver and title)\n",
    "    \n",
    "    it returns two lists, of kept (keep_lines) and removed lines (remove_lines)\n",
    "    \"\"\"\n",
    "    \n",
    "    amount_mask = fun_remove_lines2(amount)\n",
    "    year_mask = fun_remove_lines2(year)\n",
    "    rec_mask = fun_remove_lines2(receiver_1)\n",
    "    rec_name_mask = fun_remove_lines2(receiver_name)\n",
    "    rec_title_mask = fun_remove_lines2(receiver_title)\n",
    "    rec_inst_mask = fun_remove_lines2(receiver_inst)\n",
    "    descrip_mask = fun_remove_lines2(descr)\n",
    "    title_mask = fun_remove_lines2(title)\n",
    "    \n",
    "\n",
    "    grant_condition = amount_mask & year_mask\n",
    "    receiver_condition = rec_mask | rec_name_mask | rec_title_mask | rec_inst_mask \n",
    "    project_info_condition = descrip_mask | title_mask | rec_title_mask \n",
    "    \n",
    "\n",
    "    keep_mask = grant_condition & receiver_condition & project_info_condition \n",
    "    keep_lines2 = list(keep_mask[keep_mask].index)\n",
    "    remove_lines2 = list(keep_mask[~keep_mask].index)\n",
    "    \n",
    "    return keep_lines2, remove_lines2\n",
    "\n",
    "\n",
    "def detection_fun(masked_list):\n",
    "    \"\"\"\n",
    "    this function takes a list of text strings as input, \n",
    "    detects the language of the string, \n",
    "    and saves it to a list returned\n",
    "    \"\"\"\n",
    "    detection_list = []\n",
    "    for num, i in enumerate(masked_list):\n",
    "\n",
    "        if i != \"18+\" and i != \"34756600\" and pd.notna(i):\n",
    "            d = detect(i) \n",
    "            detection_list.append(d)\n",
    "        else:\n",
    "            detection_list.append(i) \n",
    "        if num % 100 == 0:\n",
    "            print(num)\n",
    "    return detection_list\n",
    "\n",
    "def translater_function(column_name, langdetect_list):\n",
    "    \"\"\"\n",
    "    This function takes a series object with text info that is to be translated. \n",
    "    It translates the text and saves the data to a new series object called translated_description\n",
    "    \"\"\"\n",
    "    translated_description_full = []\n",
    "    not_translated = []\n",
    "    index = []\n",
    "\n",
    "    for num, i in enumerate(column_name):\n",
    "        if num % 100 == 0:\n",
    "            print(num)\n",
    "        \n",
    "        if langdetect_list[num] != \"en\":\n",
    "            try:\n",
    "                item = ts.translate_text(query_text=i, if_use_preacceleration = True, if_ignore_empty_query=True)\n",
    "                translated_description_full.append(item)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error translating: {e}\")\n",
    "                translated_description_full.append(i)\n",
    "                not_translated.append(i)\n",
    "                index.append(num)\n",
    "                print(num, i)\n",
    "        else:\n",
    "            translated_description_full.append(i)\n",
    "                \n",
    "    return translated_description_full, not_translated, index\n",
    "\n",
    "\n",
    "#functions adapted from: https://www.kaggle.com/code/abdmental01/text-preprocessing-nlp-steps-to-process-text\n",
    "\n",
    "def removing_html_tags(text):\n",
    "    \"\"\"This function removes HTML tags in a given string input (text)\"\"\"\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', str(text))\n",
    "\n",
    "def removing_url(text):\n",
    "    \"\"\"This function removes URL's in a given string input (text)\"\"\"\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "punc = string.punctuation  \n",
    "def removing_string_punc(text):\n",
    "    \"\"\"This function removes string punctuations in a given string input (text)\"\"\"\n",
    "    return text.translate(str.maketrans('', '', punc))\n",
    "\n",
    "stop_words = get_stop_words('en') #initiating variable with english stop words\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"This function removes stop words from english vocabulary in a given string input (text)\"\"\"\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stop_words:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n",
    "def data_processing_function(list_of_interest):\n",
    "    \"\"\"This function takes a list or series as input, and applies each datapre-processing steps defined before,\n",
    "    and return the processed list\"\"\"\n",
    "    \n",
    "    nl = list_of_interest.astype(str).str.lower()  #Lowercase formatting\n",
    "    nl_html = nl.apply(removing_html_tags) #removing HTMLs\n",
    "    nl_url = nl_html.apply(removing_url) #removing URLs\n",
    "    nl_sp = nl_url.apply(removing_string_punc) #removing string punctuation: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    nl_stopword = nl_sp.apply(remove_stopwords) #removing stop words\n",
    "    return nl_stopword\n",
    "\n",
    "\n",
    "def non_translated_rows(non_translated_list):\n",
    "    \"\"\"\n",
    "    This function takes the \"non_translated_list\" output from the translater_function and prints and \n",
    "    saves rows that were not translated with the Translator module. \n",
    "    \n",
    "    input : non_translated_list\n",
    "    \n",
    "    return : list of strings + index that where not translated\n",
    "    \n",
    "    \"\"\"\n",
    "    non_translated_list = pd.Series(non_translated_list) \n",
    "    mask_natitle = pd.notna(non_translated_list)\n",
    "    count_title = 0\n",
    "    non_translated = non_translated_list[mask_natitle]\n",
    "    for i in non_translated:\n",
    "        s = len(i)\n",
    "        count_title += s\n",
    "\n",
    "    print(\"Rows Not tranlated with Translator module : \", len(non_translated))\n",
    "    print(\"Characters Not tranlated with Translator module : \", count_title)\n",
    "    return non_translated\n",
    "\n",
    "\n",
    "\n",
    "keeper, remover = higher_remove_function2(df['Grant_size_(DKK)'], df['Year'], df['Receiver'], df['Receiver_Name'], df['Receiver_Title'], df['Institution'], df['Description'], df['Title'])\n",
    "\n",
    "print(\"Number of lines kept :\", len(keeper))\n",
    "print(\"Number of lines removed :\", len(remover))\n",
    "\n",
    "\n",
    "df.loc[remover].to_csv('removed_rows6th_nov.csv', index=True)\n",
    "na_removed_df = df.loc[remover]  #new df\n",
    "na_removed_df = na_removed_df.reset_index() \n",
    "\n",
    "#Saving kept lines for new dataframe\n",
    "df = df.loc[keeper]  #new df\n",
    "df = df.reset_index(drop = True)  #reset index (kept old index for now as new column)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Language detect function for fast translation step \n",
    "detected_descriptionlist = detection_fun(df[\"Description\"])\n",
    "de_title = detection_fun(df[\"Title\"])\n",
    "de_receiver_title = detection_fun(df[\"Receiver_Title\"])\n",
    "\n",
    "#Lower convertion of Strings\n",
    "df[\"Description\"] = df[\"Description\"].str.lower()  \n",
    "df[\"Title\"] = df[\"Title\"].str.lower()\n",
    "df[\"Receiver_Title\"] = df[\"Receiver_Title\"].str.lower()\n",
    "\n",
    "#Translation of Description, Title and Receiver_Title\n",
    "translated_description_list, not_tra_desc, ind_desc = translater_function(df[\"Description\"], detected_descriptionlist)  #translation of description\n",
    "translated_title_list, not_tra_title, ind_title = translater_function(df[\"Title\"], de_title)  #translation of title\n",
    "translated_rec_n_title_list, not_tra_rec_dec, ind_rec_dec = translater_function(df[\"Receiver_Title\"], de_receiver_title)  #translation of rec + title list\n",
    "\n",
    "#all translations are saved to this list - except for few rows that failed - later translated with DeepL - API required\n",
    "translated_list = pd.DataFrame(\n",
    "    {'desc': translated_description_list,\n",
    "     'title': translated_title_list,\n",
    "     'rec_title': translated_rec_n_title_list\n",
    "    })\n",
    "\n",
    "#saving to csv to save results\n",
    "translated_list.to_csv(\"translated_lists_xth_month.csv\")  #saving to csv to save results\n",
    "\n",
    "\n",
    "#checking number of rows that where not translated in the 3 lists\n",
    "\n",
    "no_translation_description = non_translated_rows(not_tra_desc)\n",
    "no_translation_title = non_translated_rows(not_tra_title)\n",
    "no_translation_rec_title = non_translated_rows(not_tra_rec_dec)\n",
    "\n",
    "\n",
    "\n",
    "#The DeepL module offers 500.000 free characters translated pr. month, \n",
    "#and therefore it's enough to translate the remaining\n",
    "\n",
    "#it's only in the \"Description\" list we have untranslated 4816 rows, so we introduce deep L translator\n",
    "translator = deepl.Translator(\"caae833d-76d5-40f6-a1a6-b7badb3abd91:fx\")\n",
    "\n",
    "\n",
    "##test - remove hash if deepL is not working, to test API\n",
    "result = translator.translate_text(\"Hello, world!\", target_lang=\"FR\")\n",
    "print(result)\n",
    "\n",
    "#only run once!!\n",
    "#translate untranslated descrptions: \n",
    "\n",
    "deep_l_translations = []\n",
    "for i in no_translation_description:\n",
    "    results = translator.translate_text(i, target_lang=\"EN-US\")  #applying EN-US english \n",
    "    deep_l_translations.append(results.text)\n",
    "\n",
    "deepl_arr = np.array(deep_l_translations)\n",
    "\n",
    "translated_desc = np.array(translated_description_list) #make copy\n",
    "\n",
    "index_arr = np.array(ind_desc)\n",
    "index_no_na = index_arr[mask_natitle]  #using the masking list of nan lines from before\n",
    "print(len(index_no_na))  #Index file\n",
    "print(len(deepl_arr)) #translated file\n",
    "translated_desc[index_no_na]=deepl_arr\n",
    "\n",
    "\n",
    "df.insert(13, \"Translated_descriptions\", translated_desc, True)  #only run once!\n",
    "df.insert(11, \"Translated_title\", translated_title_list, True) #only run once!\n",
    "df.insert(12, \"Translated_receiver_title\", translated_rec_n_title_list, True) #only run once!\n",
    "\n",
    "#Data processing step\n",
    "df[\"Translated_descriptions_pro\"] = data_processing_function(df[\"Translated_descriptions\"])\n",
    "df[\"Translated_title_pro\"] = data_processing_function(df[\"Translated_title\"])\n",
    "df[\"Translated_receiver_title_pro\"] = data_processing_function(df[\"Translated_receiver_title\"])\n",
    "\n",
    "df.to_csv(\"df_translated_proc_19thnov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ac8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
