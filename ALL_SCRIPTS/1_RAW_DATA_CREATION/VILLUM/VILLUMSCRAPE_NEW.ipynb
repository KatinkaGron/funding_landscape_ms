{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f0b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page number number: 1\n",
      "page number number: 2\n",
      "page number number: 3\n",
      "page number number: 4\n",
      "page number number: 5\n",
      "page number number: 6\n",
      "page number number: 7\n",
      "page number number: 8\n",
      "page number number: 9\n",
      "page number number: 10\n",
      "page number number: 11\n",
      "page number number: 12\n",
      "page number number: 13\n",
      "page number number: 14\n",
      "page number number: 15\n",
      "page number number: 16\n",
      "page number number: 17\n",
      "page number number: 18\n",
      "page number number: 19\n",
      "page number number: 20\n",
      "page number number: 21\n",
      "page number number: 22\n",
      "page number number: 23\n",
      "page number number: 24\n",
      "page number number: 25\n",
      "page number number: 26\n",
      "page number number: 27\n",
      "page number number: 28\n",
      "page number number: 29\n",
      "page number number: 30\n",
      "page number number: 31\n",
      "page number number: 32\n",
      "page number number: 33\n",
      "page number number: 34\n",
      "page number number: 35\n",
      "page number number: 36\n",
      "page number number: 37\n",
      "page number number: 38\n",
      "page number number: 39\n",
      "page number number: 40\n",
      "page number number: 41\n",
      "page number number: 42\n",
      "page number number: 43\n",
      "page number number: 44\n",
      "page number number: 45\n",
      "page number number: 46\n",
      "page number number: 47\n",
      "page number number: 48\n",
      "Loop ended\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "def extract_data_villum(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will collect the grant information provided from the Villum foundation grant database with the url: \"https://villumfonden.dk/da/simpel-side/det-har-vi-stoettet-projektoversigt-fra-1971?calcbrowser.view_name.value=bars_horizontal_year&calcbrowser.university.value=0\"\n",
    "    \n",
    "    The paths are found using devtools, and found through the webpage.\n",
    "    \n",
    "    note: When the window opens, one must actively choose a web browser (eg. Ecosia) and close the\n",
    "    the Cookie popup window - to start the extraction. \n",
    "    \n",
    "    The information is saved in the lists of the following groups:\n",
    "    title_l = []\n",
    "    amount_L = []\n",
    "    receiver_l = []\n",
    "    project_cat1_l = []\n",
    "    project_cat2_l = []\n",
    "    \n",
    "    and if data is not avaiable for a certain group, then \"NA\" is inserted. \n",
    "    \n",
    "    The lists are finally zipped together in the biglist dataframe.\n",
    "    \n",
    "    input: target_url (https://villumfonden.dk/da/simpel-side/det-har-vi-stoettet-projektoversigt-fra-1971?calcbrowser.view_name.value=bars_horizontal_year&calcbrowser.university.value=0\")\n",
    "    return: Dataframe with text extracted\n",
    "    \"\"\"    \n",
    "\n",
    "    title_l = []\n",
    "    amount_L = []\n",
    "    receiver_l = []\n",
    "    project_cat1_l = []\n",
    "    project_cat2_l = []\n",
    "    \n",
    "    \n",
    "    stored_description_lack_info = []\n",
    "    \n",
    "    \n",
    "    driver.get(url)\n",
    "    driver.maximize_window() #opening full web browser window\n",
    "    time.sleep(5)\n",
    "    \n",
    "    action = ActionChains(driver)\n",
    "    \n",
    "    #click on table button\n",
    "    ActionChains(driver).move_to_element(driver.find_element(By.CSS_SELECTOR, \"#block-b14theme-content > article > div.calc-browser > div.calc-browser-table > div > div.calc-browser-table-header > div.calc-browser-table-type > a.table-show-table\")).perform()  #move to place\n",
    "    time.sleep(5)\n",
    "    driver.find_element(By.CSS_SELECTOR, \"#block-b14theme-content > article > div.calc-browser > div.calc-browser-table > div > div.calc-browser-table-header > div.calc-browser-table-type > a.table-show-table\").click()\n",
    "    \n",
    "    try:\n",
    "        for page_num in range(1,50): #49 is full number (run again)\n",
    "            \"\"\"we click next page 49 times\"\"\"\n",
    "            #time.sleep(5)\n",
    "            \n",
    "            #ActionChains(driver).move_to_element(driver.find_element(By.XPATH, \"/html/body/div[2]/main/div/div/article/div[2]/div[1]/div/div/div[2]/table/tbody/tr[1]/td[1]\")).perform()  #move to place\n",
    "            for i in range(1,51):\n",
    "                time.sleep(2)\n",
    "                action.move_to_element(driver.find_element(By.XPATH, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[1]/a\")).perform()  #move to the line of interest\n",
    "                \n",
    "                #title\n",
    "                find_element_function(title_l, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[1]/a\")\n",
    "                \n",
    "                #amount\n",
    "                find_element_function(amount_L, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[2]/span[2]\")\n",
    "                \n",
    "                #receiver\n",
    "                find_element_function(receiver_l, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[3]\")\n",
    "                \n",
    "                #project_cat1_l\n",
    "                find_element_function(project_cat1_l, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[4]\")\n",
    "                \n",
    "                #project_cat2_l\n",
    "                find_element_function(project_cat2_l, f\"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[2]/table/tbody/tr[{i}]/td[5]\")\n",
    "                \n",
    "                \n",
    "\n",
    "                if i == 50:\n",
    "                    ActionChains(driver).move_to_element(driver.find_element(By.XPATH, \"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[3]/div[2]/a[2]\")).perform()  #move to click button\n",
    "                    element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div/div/main/div[2]/div[2]/div/article/div[2]/div[2]/div/div[2]/div[3]/div[2]/a[2]\")))\n",
    "                    element.click()\n",
    "                    print(\"page number number:\", page_num)\n",
    "                    time.sleep(5)\n",
    "                \n",
    "                    \n",
    "            \n",
    "    except NoSuchElementException: #avoid programme crashing\n",
    "        print(\"Loop ended\")\n",
    "\n",
    " \n",
    "\n",
    "    df_final = pd.DataFrame(list(zip(title_l, amount_L, receiver_l, project_cat1_l, project_cat2_l)), columns=[\"Title\", 'Grant size (DKK)', 'Reciever', 'Project_category', \"Project_subcategory\"])\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "def find_element_function(listname, x_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    helper function, that will first try to find the right element, \n",
    "    and if an error is raied, it will insert an \"NA\" instead\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        text_found = driver.find_element(By.XPATH, x_path).text\n",
    "        listname.append(text_found)\n",
    "    except ElementClickInterceptedException:\n",
    "        text_found = \"NA\"\n",
    "        listname.append(location)\n",
    "    except StaleElementReferenceException:\n",
    "        text_found = \"NA\"\n",
    "        listname.append(location)\n",
    "    except NoSuchElementException:\n",
    "        text_found = \"NA\"\n",
    "        listname.append(text_found)\n",
    "        \n",
    "        return\n",
    "\n",
    "biglist = extract_data_villum(\"https://villumfonden.dk/da/simpel-side/det-har-vi-stoettet-projektoversigt-fra-1971?calcbrowser.view_name.value=bars_horizontal_year&calcbrowser.university.value=0\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "biglist.to_csv(\"villum_rawdata_mio.csv\") #if there is an error downstream, it is saved here first\n",
    "biglist_new = biglist\n",
    "biglist_new = biglist_new.rename(columns={\"Reciever\": \"Receiver\"})\n",
    "biglist_new[\"Grant size (DKK)\"] = biglist_new[\"Grant size (DKK)\"].str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\")\n",
    "biglist_new[\"Grant size (DKK)\"] = biglist_new[\"Grant size (DKK)\"].str.replace(\" kr\", \"\", regex=False)\n",
    "\n",
    "mio_entries = biglist_new[\"Grant size (DKK)\"].str.contains(\"mio\", na=False)\n",
    "mio_entrie_print = biglist_new[\"Grant size (DKK)\"][mio_entries]\n",
    "mio_no_str = mio_entrie_print.str.replace(\"mio\", \"\")\n",
    "mio_no_numeric = pd.to_numeric(mio_no_str, errors='coerce')\n",
    "new_mio_integers = (mio_no_numeric*1000000).astype(int)\n",
    "biglist_new[\"Grant size (DKK)\"][new_mio_integers.index] = new_mio_integers\n",
    "biglist_new = biglist_new.iloc[:-1]\n",
    "biglist_new\n",
    "biglist_new.to_csv(\"villum_rawdata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
